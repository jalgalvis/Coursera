{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "from tf_utils import load_dataset, random_mini_batches, convert_to_one_hot, predict\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "y_hat = tf.constant(36, name='y_hat')            # Define y_hat constant. Set to 36.\n",
    "y = tf.constant(39, name='y')                    # Define y. Set to 39\n",
    "\n",
    "loss = tf.Variable((y - y_hat)**2, name='loss')  # Create a variable for the loss\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "# When init is run later (session.run(init)),\n",
    "                                                 # the loss variable will be initialized and ready to be computed\n",
    "with tf.Session() as session:                    # Create a session and print the output\n",
    "    session.run(init)                            # Initializes the variables\n",
    "    print(session.run(loss))                     # Prints the loss\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Mul:0\", shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "a = tf.constant(2)\n",
    "b = tf.constant(10)\n",
    "c = tf.multiply(a,b)\n",
    "print(c)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "print(sess.run(c))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "# Change the value of x in the feed_dict\n",
    "\n",
    "x = tf.placeholder(tf.int64, name = 'x')\n",
    "print(sess.run(2 * x, feed_dict = {x: 3}))\n",
    "sess.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: linear_function\n",
    "\n",
    "def linear_function():\n",
    "    \"\"\"\n",
    "    Implements a linear function:\n",
    "            Initializes X to be a random tensor of shape (3,1)\n",
    "            Initializes W to be a random tensor of shape (4,3)\n",
    "            Initializes b to be a random tensor of shape (4,1)\n",
    "    Returns:\n",
    "    result -- runs the session for Y = WX + b\n",
    "    \"\"\"\n",
    "\n",
    "    np.random.seed(1)\n",
    "\n",
    "    \"\"\"\n",
    "    Note, to ensure that the \"random\" numbers generated match the expected results,\n",
    "    please create the variables in the order given in the starting code below.\n",
    "    (Do not re-arrange the order).\n",
    "    \"\"\"\n",
    "    ### START CODE HERE ### (4 lines of code)\n",
    "    X = tf.constant(np.random.randn(3,1), name = \"X\")\n",
    "    W = tf.constant(np.random.randn(4,3), name = \"W\")\n",
    "    b = tf.constant(np.random.randn(4,1), name = \"b\")\n",
    "    Y = tf.add(tf.matmul(W, X), b)\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    # Create the session using tf.Session() and run it with sess.run(...) on the variable you want to calculate\n",
    "\n",
    "    ### START CODE HERE ###\n",
    "    sess = tf.Session()\n",
    "    result = sess.run(Y)\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    # close the session\n",
    "    sess.close()\n",
    "\n",
    "    return result"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result = \n",
      "[[-2.15657382]\n",
      " [ 2.95891446]\n",
      " [-1.08926781]\n",
      " [-0.84538042]]\n"
     ]
    }
   ],
   "source": [
    "print( \"result = \\n\" + str(linear_function()))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: sigmoid\n",
    "\n",
    "def sigmoid(z):\n",
    "    \"\"\"\n",
    "    Computes the sigmoid of z\n",
    "\n",
    "    Arguments:\n",
    "    z -- input value, scalar or vector\n",
    "\n",
    "    Returns:\n",
    "    results -- the sigmoid of z\n",
    "    \"\"\"\n",
    "\n",
    "    ### START CODE HERE ### ( approx. 4 lines of code)\n",
    "    # Create a placeholder for x. Name it 'x'.\n",
    "    x = tf.placeholder(tf.float32, name = \"x\")\n",
    "\n",
    "    # compute sigmoid(x)\n",
    "    sigmoid = tf.sigmoid(x)\n",
    "\n",
    "    # Create a session, and run it. Please use the method 2 explained above.\n",
    "    # You should use a feed_dict to pass z's value to x.\n",
    "    sess = tf.Session()\n",
    "    # Run session and call the output \"result\"\n",
    "    result = sess.run(sigmoid, feed_dict = {x: z})\n",
    "\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    return result\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigmoid(0) = 0.5\n",
      "sigmoid(12) = 0.9999938\n"
     ]
    }
   ],
   "source": [
    "print (\"sigmoid(0) = \" + str(sigmoid(0)))\n",
    "print (\"sigmoid(12) = \" + str(sigmoid(12)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: cost\n",
    "\n",
    "def cost(logits, labels):\n",
    "    \"\"\"\n",
    "    Computes the cost using the sigmoid cross entropy\n",
    "    \n",
    "    Arguments:\n",
    "    logits -- vector containing z, output of the last linear unit (before the final sigmoid activation)\n",
    "    labels -- vector of labels y (1 or 0)\n",
    "\n",
    "    Note: What we've been calling \"z\" and \"y\" in this class are respectively called \"logits\" and \"labels\"\n",
    "    in the TensorFlow documentation. So logits will feed into z, and labels into y.\n",
    "    \n",
    "    Returns:\n",
    "    cost -- runs the session of the cost (formula (2))\n",
    "    \"\"\"\n",
    "\n",
    "    ### START CODE HERE ###\n",
    "\n",
    "    # Create the placeholders for \"logits\" (z) and \"labels\" (y) (approx. 2 lines)\n",
    "    z = tf.placeholder(tf.float64, name= 'z')\n",
    "    y = tf.placeholder(tf.float64, name= 'y')\n",
    "\n",
    "    # Use the loss function (approx. 1 line)\n",
    "    cost = tf.nn.sigmoid_cross_entropy_with_logits(logits = z,  labels = y)\n",
    "\n",
    "    # Create a session (approx. 1 line). See method 1 above.\n",
    "    sess = tf.Session()\n",
    "\n",
    "    # Run the session (approx. 1 line).\n",
    "    cost = sess.run(cost, feed_dict={z : logits, y: labels})\n",
    "\n",
    "    # Close the session (approx. 1 line). See method 1 above.\n",
    "    sess.close()\n",
    "\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    return cost"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/jalejo/.conda/envs/DeepLearning1/lib/python3.7/site-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "cost = [0.79813887 0.91301525 0.40318605 0.34115387]\n"
     ]
    }
   ],
   "source": [
    "logits = np.array([0.2,0.4,0.7,0.9])\n",
    "\n",
    "cost = cost(logits, np.array([0,0,1,1]))\n",
    "print (\"cost = \" + str(cost))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: one_hot_matrix\n",
    "\n",
    "def one_hot_matrix(labels, C):\n",
    "    \"\"\"\n",
    "    Creates a matrix where the i-th row corresponds to the ith class number and the jth column\n",
    "                     corresponds to the jth training example. So if example j had a label i. Then entry (i,j)\n",
    "                     will be 1.\n",
    "\n",
    "    Arguments:\n",
    "    labels -- vector containing the labels\n",
    "    C -- number of classes, the depth of the one hot dimension\n",
    "\n",
    "    Returns:\n",
    "    one_hot -- one hot matrix\n",
    "    \"\"\"\n",
    "\n",
    "    ### START CODE HERE ###\n",
    "\n",
    "    # Create a tf.constant equal to C (depth), name it 'C'. (approx. 1 line)\n",
    "    C = tf.constant(C, name = \"C\")\n",
    "\n",
    "    # Use tf.one_hot, be careful with the axis (approx. 1 line)\n",
    "    one_hot_matrix = tf.one_hot(labels, C, axis=0)\n",
    "\n",
    "    # Create the session (approx. 1 line)\n",
    "    sess = tf.Session()\n",
    "\n",
    "    # Run the session (approx. 1 line)\n",
    "    one_hot = sess.run(one_hot_matrix)\n",
    "\n",
    "    # Close the session (approx. 1 line). See method 1 above.\n",
    "    sess.close()\n",
    "\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    return one_hot"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one_hot = \n",
      "[[0. 0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 1.]\n",
      " [0. 1. 0. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "labels = np.array([1,2,3,0,2,1])\n",
    "one_hot = one_hot_matrix(labels, C = 4)\n",
    "print (\"one_hot = \\n\" + str(one_hot))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: ones\n",
    "\n",
    "def ones(shape):\n",
    "    \"\"\"\n",
    "    Creates an array of ones of dimension shape\n",
    "\n",
    "    Arguments:\n",
    "    shape -- shape of the array you want to create\n",
    "\n",
    "    Returns:\n",
    "    ones -- array containing only ones\n",
    "    \"\"\"\n",
    "\n",
    "    ### START CODE HERE ###\n",
    "\n",
    "    # Create \"ones\" tensor using tf.ones(...). (approx. 1 line)\n",
    "    ones = tf.ones(shape)\n",
    "\n",
    "    # Create the session (approx. 1 line)\n",
    "    sess = tf.Session()\n",
    "\n",
    "    # Run the session to compute 'ones' (approx. 1 line)\n",
    "    ones = sess.run(ones)\n",
    "\n",
    "    # Close the session (approx. 1 line). See method 1 above.\n",
    "    sess.close()\n",
    "\n",
    "    ### END CODE HERE ###\n",
    "    return ones"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ones = [1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "print (\"ones = \" + str(ones([3])))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "# Loading the dataset\n",
    "X_train_orig, Y_train_orig, X_test_orig, Y_test_orig, classes = load_dataset()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y = 5\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example of a picture\n",
    "index = 0\n",
    "plt.imshow(X_train_orig[index])\n",
    "print (\"y = \" + str(np.squeeze(Y_train_orig[:, index])))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training examples = 1080\n",
      "number of test examples = 120\n",
      "X_train shape: (12288, 1080)\n",
      "Y_train shape: (6, 1080)\n",
      "X_test shape: (12288, 120)\n",
      "Y_test shape: (6, 120)\n"
     ]
    }
   ],
   "source": [
    "# Flatten the training and test images\n",
    "X_train_flatten = X_train_orig.reshape(X_train_orig.shape[0], -1).T\n",
    "X_test_flatten = X_test_orig.reshape(X_test_orig.shape[0], -1).T\n",
    "# Normalize image vectors\n",
    "X_train = X_train_flatten/255.\n",
    "X_test = X_test_flatten/255.\n",
    "# Convert training and test labels to one hot matrices\n",
    "Y_train = convert_to_one_hot(Y_train_orig, 6)\n",
    "Y_test = convert_to_one_hot(Y_test_orig, 6)\n",
    "\n",
    "print (\"number of training examples = \" + str(X_train.shape[1]))\n",
    "print (\"number of test examples = \" + str(X_test.shape[1]))\n",
    "print (\"X_train shape: \" + str(X_train.shape))\n",
    "print (\"Y_train shape: \" + str(Y_train.shape))\n",
    "print (\"X_test shape: \" + str(X_test.shape))\n",
    "print (\"Y_test shape: \" + str(Y_test.shape))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: create_placeholders\n",
    "\n",
    "def create_placeholders(n_x, n_y):\n",
    "    \"\"\"\n",
    "    Creates the placeholders for the tensorflow session.\n",
    "\n",
    "    Arguments:\n",
    "    n_x -- scalar, size of an image vector (num_px * num_px = 64 * 64 * 3 = 12288)\n",
    "    n_y -- scalar, number of classes (from 0 to 5, so -> 6)\n",
    "\n",
    "    Returns:\n",
    "    X -- placeholder for the data input, of shape [n_x, None] and dtype \"tf.float32\"\n",
    "    Y -- placeholder for the input labels, of shape [n_y, None] and dtype \"tf.float32\"\n",
    "\n",
    "    Tips:\n",
    "    - You will use None because it let's us be flexible on the number of examples you will for the placeholders.\n",
    "      In fact, the number of examples during test/train is different.\n",
    "    \"\"\"\n",
    "\n",
    "    ### START CODE HERE ### (approx. 2 lines)\n",
    "    X = tf.placeholder(dtype=tf.float32, shape=[n_x, None], name='X')\n",
    "    Y = tf.placeholder(dtype=tf.float32, shape=[n_y, None], name='Y')\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    return X, Y"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X = Tensor(\"X_4:0\", shape=(12288, ?), dtype=float32)\n",
      "Y = Tensor(\"Y_2:0\", shape=(6, ?), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "X, Y = create_placeholders(12288, 6)\n",
    "print (\"X = \" + str(X))\n",
    "print (\"Y = \" + str(Y))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: initialize_parameters\n",
    "\n",
    "def initialize_parameters():\n",
    "    \"\"\"\n",
    "    Initializes parameters to build a neural network with tensorflow. The shapes are:\n",
    "                        W1 : [25, 12288]\n",
    "                        b1 : [25, 1]\n",
    "                        W2 : [12, 25]\n",
    "                        b2 : [12, 1]\n",
    "                        W3 : [6, 12]\n",
    "                        b3 : [6, 1]\n",
    "\n",
    "    Returns:\n",
    "    parameters -- a dictionary of tensors containing W1, b1, W2, b2, W3, b3\n",
    "    \"\"\"\n",
    "\n",
    "    tf.set_random_seed(1)                   # so that your \"random\" numbers match ours\n",
    "\n",
    "    ### START CODE HERE ### (approx. 6 lines of code)\n",
    "    W1 = tf.get_variable(\"W1\", [25,12288], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    b1 = tf.get_variable(\"b1\", [25,1], initializer = tf.zeros_initializer())\n",
    "    W2 = tf.get_variable(\"W2\", [12,25], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    b2 = tf.get_variable(\"b2\", [12,1], initializer = tf.zeros_initializer())\n",
    "    W3 = tf.get_variable(\"W3\", [6,12], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    b3 = tf.get_variable(\"b3\", [6,1], initializer = tf.zeros_initializer())\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"b1\": b1,\n",
    "                  \"W2\": W2,\n",
    "                  \"b2\": b2,\n",
    "                  \"W3\": W3,\n",
    "                  \"b3\": b3}\n",
    "\n",
    "    return parameters"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "W1 = <tf.Variable 'W1:0' shape=(25, 12288) dtype=float32_ref>\n",
      "b1 = <tf.Variable 'b1:0' shape=(25, 1) dtype=float32_ref>\n",
      "W2 = <tf.Variable 'W2:0' shape=(12, 25) dtype=float32_ref>\n",
      "b2 = <tf.Variable 'b2:0' shape=(12, 1) dtype=float32_ref>\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "with tf.Session() as sess:\n",
    "    parameters = initialize_parameters()\n",
    "    print(\"W1 = \" + str(parameters[\"W1\"]))\n",
    "    print(\"b1 = \" + str(parameters[\"b1\"]))\n",
    "    print(\"W2 = \" + str(parameters[\"W2\"]))\n",
    "    print(\"b2 = \" + str(parameters[\"b2\"]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: forward_propagation\n",
    "\n",
    "def forward_propagation(X, parameters):\n",
    "    \"\"\"\n",
    "    Implements the forward propagation for the model: LINEAR -> RELU -> LINEAR -> RELU -> LINEAR -> SOFTMAX\n",
    "\n",
    "    Arguments:\n",
    "    X -- input dataset placeholder, of shape (input size, number of examples)\n",
    "    parameters -- python dictionary containing your parameters \"W1\", \"b1\", \"W2\", \"b2\", \"W3\", \"b3\"\n",
    "                  the shapes are given in initialize_parameters\n",
    "\n",
    "    Returns:\n",
    "    Z3 -- the output of the last LINEAR unit\n",
    "    \"\"\"\n",
    "\n",
    "    # Retrieve the parameters from the dictionary \"parameters\"\n",
    "    W1 = parameters['W1']\n",
    "    b1 = parameters['b1']\n",
    "    W2 = parameters['W2']\n",
    "    b2 = parameters['b2']\n",
    "    W3 = parameters['W3']\n",
    "    b3 = parameters['b3']\n",
    "\n",
    "    ### START CODE HERE ### (approx. 5 lines)              # Numpy Equivalents:\n",
    "    Z1 = tf.add(tf.matmul(W1, X), b1)                                              # Z1 = np.dot(W1, X) + b1\n",
    "    A1 = tf.nn.relu(Z1)                                              # A1 = relu(Z1)\n",
    "    Z2 = tf.add(tf.matmul(W2, A1), b2)                                              # Z2 = np.dot(W2, A1) + b2\n",
    "    A2 = tf.nn.relu(Z2)                                              # A2 = relu(Z2)\n",
    "    Z3 = tf.add(tf.matmul(W3, A2), b3)                                              # Z3 = np.dot(W3, A2) + b3\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    return Z3"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z3 = Tensor(\"Add_2:0\", shape=(6, ?), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    X, Y = create_placeholders(12288, 6)\n",
    "    parameters = initialize_parameters()\n",
    "    Z3 = forward_propagation(X, parameters)\n",
    "    print(\"Z3 = \" + str(Z3))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: compute_cost\n",
    "\n",
    "def compute_cost(Z3, Y):\n",
    "    \"\"\"\n",
    "    Computes the cost\n",
    "\n",
    "    Arguments:\n",
    "    Z3 -- output of forward propagation (output of the last LINEAR unit), of shape (6, number of examples)\n",
    "    Y -- \"true\" labels vector placeholder, same shape as Z3\n",
    "\n",
    "    Returns:\n",
    "    cost - Tensor of the cost function\n",
    "    \"\"\"\n",
    "\n",
    "    # to fit the tensorflow requirement for tf.nn.softmax_cross_entropy_with_logits(...,...)\n",
    "    logits = tf.transpose(Z3)\n",
    "    labels = tf.transpose(Y)\n",
    "\n",
    "    ### START CODE HERE ### (1 line of code)\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = logits, labels = labels))\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    return cost"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-25-da13b5ec9b07>:20: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "cost = Tensor(\"Mean:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    X, Y = create_placeholders(12288, 6)\n",
    "    parameters = initialize_parameters()\n",
    "    Z3 = forward_propagation(X, parameters)\n",
    "    cost = compute_cost(Z3, Y)\n",
    "    print(\"cost = \" + str(cost))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "def model(X_train, Y_train, X_test, Y_test, learning_rate = 0.0001,\n",
    "          num_epochs = 1500, minibatch_size = 32, print_cost = True):\n",
    "    \"\"\"\n",
    "    Implements a three-layer tensorflow neural network: LINEAR->RELU->LINEAR->RELU->LINEAR->SOFTMAX.\n",
    "\n",
    "    Arguments:\n",
    "    X_train -- training set, of shape (input size = 12288, number of training examples = 1080)\n",
    "    Y_train -- test set, of shape (output size = 6, number of training examples = 1080)\n",
    "    X_test -- training set, of shape (input size = 12288, number of training examples = 120)\n",
    "    Y_test -- test set, of shape (output size = 6, number of test examples = 120)\n",
    "    learning_rate -- learning rate of the optimization\n",
    "    num_epochs -- number of epochs of the optimization loop\n",
    "    minibatch_size -- size of a minibatch\n",
    "    print_cost -- True to print the cost every 100 epochs\n",
    "\n",
    "    Returns:\n",
    "    parameters -- parameters learnt by the model. They can then be used to predict.\n",
    "    \"\"\"\n",
    "\n",
    "    ops.reset_default_graph()                         # to be able to rerun the model without overwriting tf variables\n",
    "    tf.set_random_seed(1)                             # to keep consistent results\n",
    "    seed = 3                                          # to keep consistent results\n",
    "    (n_x, m) = X_train.shape                          # (n_x: input size, m : number of examples in the train set)\n",
    "    n_y = Y_train.shape[0]                            # n_y : output size\n",
    "    costs = []                                        # To keep track of the cost\n",
    "\n",
    "    # Create Placeholders of shape (n_x, n_y)\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    X, Y = create_placeholders(n_x, n_y)\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    # Initialize parameters\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    parameters = initialize_parameters()\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    # Forward propagation: Build the forward propagation in the tensorflow graph\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    Z3 = forward_propagation(X, parameters)\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    # Cost function: Add cost function to tensorflow graph\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    cost = compute_cost(Z3, Y)\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    # Backpropagation: Define the tensorflow optimizer. Use an AdamOptimizer.\n",
    "    ### START CODE HERE ### (1 line)\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    # Initialize all the variables\n",
    "    init = tf.global_variables_initializer()\n",
    "\n",
    "    # Start the session to compute the tensorflow graph\n",
    "    with tf.Session() as sess:\n",
    "\n",
    "        # Run the initialization\n",
    "        sess.run(init)\n",
    "\n",
    "        # Do the training loop\n",
    "        for epoch in range(num_epochs):\n",
    "\n",
    "            epoch_cost = 0.                       # Defines a cost related to an epoch\n",
    "            num_minibatches = int(m / minibatch_size) # number of minibatches of size minibatch_size in the train set\n",
    "            seed = seed + 1\n",
    "            minibatches = random_mini_batches(X_train, Y_train, minibatch_size, seed)\n",
    "\n",
    "            for minibatch in minibatches:\n",
    "\n",
    "                # Select a minibatch\n",
    "                (minibatch_X, minibatch_Y) = minibatch\n",
    "\n",
    "                # IMPORTANT: The line that runs the graph on a minibatch.\n",
    "                # Run the session to execute the \"optimizer\" and the \"cost\", the feedict should contain a minibatch for (X,Y).\n",
    "                ### START CODE HERE ### (1 line)\n",
    "                _ , minibatch_cost = sess.run([optimizer, cost], feed_dict={X: minibatch_X, Y: minibatch_Y})\n",
    "                ### END CODE HERE ###\n",
    "\n",
    "                epoch_cost += minibatch_cost / minibatch_size\n",
    "\n",
    "            # Print the cost every epoch\n",
    "            if print_cost == True and epoch % 100 == 0:\n",
    "                print (\"Cost after epoch %i: %f\" % (epoch, epoch_cost))\n",
    "            if print_cost == True and epoch % 5 == 0:\n",
    "                costs.append(epoch_cost)\n",
    "\n",
    "        # plot the cost\n",
    "        plt.plot(np.squeeze(costs))\n",
    "        plt.ylabel('cost')\n",
    "        plt.xlabel('iterations (per fives)')\n",
    "        plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "        plt.show()\n",
    "\n",
    "        # lets save the parameters in a variable\n",
    "        parameters = sess.run(parameters)\n",
    "        print (\"Parameters have been trained!\")\n",
    "\n",
    "        # Calculate the correct predictions\n",
    "        correct_prediction = tf.equal(tf.argmax(Z3), tf.argmax(Y))\n",
    "\n",
    "        # Calculate accuracy on the test set\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "\n",
    "        print (\"Train Accuracy:\", accuracy.eval({X: X_train, Y: Y_train}))\n",
    "        print (\"Test Accuracy:\", accuracy.eval({X: X_test, Y: Y_test}))\n",
    "\n",
    "        return parameters"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "parameters = model(X_train, Y_train, X_test, Y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-35144968",
   "language": "python",
   "display_name": "PyCharm (DeepLearning)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}