{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (5.0, 4.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "params = {\"ytick.color\" : \"w\",\n",
    "          \"xtick.color\" : \"w\",\n",
    "          \"axes.labelcolor\" : \"w\",\n",
    "          \"axes.edgecolor\" : \"y\",\n",
    "          \"axes.facecolor\" : \"None\",\n",
    "          \"text.color\" : 'w'}\n",
    "plt.rcParams.update(params)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: zero_pad\n",
    "\n",
    "def zero_pad(X, pad):\n",
    "    \"\"\"\n",
    "    Pad with zeros all images of the dataset X. The padding is applied to the height and width of an image,\n",
    "    as illustrated in Figure 1.\n",
    "\n",
    "    Argument:\n",
    "    X -- python numpy array of shape (m, n_H, n_W, n_C) representing a batch of m images\n",
    "    pad -- integer, amount of padding around each image on vertical and horizontal dimensions\n",
    "\n",
    "    Returns:\n",
    "    X_pad -- padded image of shape (m, n_H + 2*pad, n_W + 2*pad, n_C)\n",
    "    \"\"\"\n",
    "\n",
    "    ### START CODE HERE ### (≈ 1 line)\n",
    "    X_pad = np.pad(X, ((0,0), (pad, pad), (pad, pad), (0,0)), mode='constant', constant_values = (0,0))\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    return X_pad"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape =\n",
      " (4, 3, 3, 2)\n",
      "x_pad.shape =\n",
      " (4, 7, 7, 2)\n",
      "x[1,1] =\n",
      " [[ 0.90085595 -0.68372786]\n",
      " [-0.12289023 -0.93576943]\n",
      " [-0.26788808  0.53035547]]\n",
      "x_pad[1,1] =\n",
      " [[0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": "<matplotlib.image.AxesImage at 0x7fa0baea6290>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 360x288 with 2 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "dark"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "x = np.random.randn(4, 3, 3, 2)\n",
    "x_pad = zero_pad(x, 2)\n",
    "print (\"x.shape =\\n\", x.shape)\n",
    "print (\"x_pad.shape =\\n\", x_pad.shape)\n",
    "print (\"x[1,1] =\\n\", x[1,1])\n",
    "print (\"x_pad[1,1] =\\n\", x_pad[1,1])\n",
    "\n",
    "fig, axarr = plt.subplots(1, 2)\n",
    "axarr[0].set_title('x')\n",
    "axarr[0].imshow(x[0,:,:,0])\n",
    "axarr[1].set_title('x_pad')\n",
    "axarr[1].imshow(x_pad[0,:,:,0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: conv_single_step\n",
    "\n",
    "def conv_single_step(a_slice_prev, W, b):\n",
    "    \"\"\"\n",
    "    Apply one filter defined by parameters W on a single slice (a_slice_prev) of the output activation\n",
    "    of the previous layer.\n",
    "\n",
    "    Arguments:\n",
    "    a_slice_prev -- slice of input data of shape (f, f, n_C_prev)\n",
    "    W -- Weight parameters contained in a window - matrix of shape (f, f, n_C_prev)\n",
    "    b -- Bias parameters contained in a window - matrix of shape (1, 1, 1)\n",
    "\n",
    "    Returns:\n",
    "    Z -- a scalar value, the result of convolving the sliding window (W, b) on a slice x of the input data\n",
    "    \"\"\"\n",
    "\n",
    "    ### START CODE HERE ### (≈ 2 lines of code)\n",
    "    # Element-wise product between a_slice_prev and W. Do not add the bias yet.\n",
    "    s = a_slice_prev * W\n",
    "    # Sum over all entries of the volume s.\n",
    "    Z = np.sum(s)\n",
    "    # Add bias b to Z. Cast b to a float() so that Z results in a scalar value.\n",
    "    Z = Z + float(b)\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    return Z"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z = -6.999089450680221\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "a_slice_prev = np.random.randn(4, 4, 3)\n",
    "W = np.random.randn(4, 4, 3)\n",
    "b = np.random.randn(1, 1, 1)\n",
    "\n",
    "Z = conv_single_step(a_slice_prev, W, b)\n",
    "print(\"Z =\", Z)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: conv_forward\n",
    "\n",
    "def conv_forward(A_prev, W, b, hparameters):\n",
    "    \"\"\"\n",
    "    Implements the forward propagation for a convolution function\n",
    "\n",
    "    Arguments:\n",
    "    A_prev -- output activations of the previous layer,\n",
    "        numpy array of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
    "    W -- Weights, numpy array of shape (f, f, n_C_prev, n_C)\n",
    "    b -- Biases, numpy array of shape (1, 1, 1, n_C)\n",
    "    hparameters -- python dictionary containing \"stride\" and \"pad\"\n",
    "\n",
    "    Returns:\n",
    "    Z -- conv output, numpy array of shape (m, n_H, n_W, n_C)\n",
    "    cache -- cache of values needed for the conv_backward() function\n",
    "    \"\"\"\n",
    "\n",
    "    ### START CODE HERE ###\n",
    "    # Retrieve dimensions from A_prev's shape (≈1 line)\n",
    "    (m, n_H_prev, n_W_prev, n_C_prev) = A_prev.shape\n",
    "\n",
    "    # Retrieve dimensions from W's shape (≈1 line)\n",
    "    (f, f, n_C_prev, n_C) = W.shape\n",
    "\n",
    "    # Retrieve information from \"hparameters\" (≈2 lines)\n",
    "    stride = hparameters['stride']\n",
    "    pad = hparameters['pad']\n",
    "\n",
    "    # Compute the dimensions of the CONV output volume using the formula given above.\n",
    "    # Hint: use int() to apply the 'floor' operation. (≈2 lines)\n",
    "    n_H = int((n_H_prev - f + 2 * pad) / stride) + 1\n",
    "    n_W = int((n_W_prev - f + 2 * pad) / stride) + 1\n",
    "\n",
    "    # Initialize the output volume Z with zeros. (≈1 line)\n",
    "    Z = np.zeros((m, n_H, n_W, n_C))\n",
    "\n",
    "    # Create A_prev_pad by padding A_prev\n",
    "    A_prev_pad = zero_pad(A_prev, pad)\n",
    "\n",
    "    for i in range(m):               # loop over the batch of training examples\n",
    "        a_prev_pad = A_prev_pad[i,:,:,:]               # Select ith training example's padded activation\n",
    "        for h in range(n_H):           # loop over vertical axis of the output volume\n",
    "            # Find the vertical start and end of the current \"slice\" (≈2 lines)\n",
    "            vert_start = h * stride\n",
    "            vert_end = vert_start + f\n",
    "\n",
    "            for w in range(n_W):       # loop over horizontal axis of the output volume\n",
    "                # Find the horizontal start and end of the current \"slice\" (≈2 lines)\n",
    "                horiz_start = w * stride\n",
    "                horiz_end = horiz_start + f\n",
    "\n",
    "                for c in range(n_C):   # loop over channels (= #filters) of the output volume\n",
    "\n",
    "                    # Use the corners to define the (3D) slice of a_prev_pad (See Hint above the cell). (≈1 line)\n",
    "                    a_slice_prev = a_prev_pad[vert_start:vert_end, horiz_start : horiz_end, :]\n",
    "\n",
    "                    # Convolve the (3D) slice with the correct filter W and bias b, to get back one output neuron. (≈3 line)\n",
    "                    weights = W[:,:,:,c]\n",
    "                    biases = b[:,:,:,c]\n",
    "                    Z[i, h, w, c] = conv_single_step(a_slice_prev, weights, biases)\n",
    "\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    # Making sure your output shape is correct\n",
    "    assert(Z.shape == (m, n_H, n_W, n_C))\n",
    "\n",
    "    # Save information in \"cache\" for the backprop\n",
    "    cache = (A_prev, W, b, hparameters)\n",
    "\n",
    "    return Z, cache\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z's mean =\n",
      " 0.6923608807576933\n",
      "Z[3,2,1] =\n",
      " [-1.28912231  2.27650251  6.61941931  0.95527176  8.25132576  2.31329639\n",
      " 13.00689405  2.34576051]\n",
      "cache_conv[0][1][2][3] =\n",
      " [-1.1191154   1.9560789  -0.3264995  -1.34267579]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "A_prev = np.random.randn(10,5,7,4)\n",
    "W = np.random.randn(3,3,4,8)\n",
    "b = np.random.randn(1,1,1,8)\n",
    "hparameters = {\"pad\" : 1,\n",
    "               \"stride\": 2}\n",
    "\n",
    "Z, cache_conv = conv_forward(A_prev, W, b, hparameters)\n",
    "print(\"Z's mean =\\n\", np.mean(Z))\n",
    "print(\"Z[3,2,1] =\\n\", Z[3,2,1])\n",
    "print(\"cache_conv[0][1][2][3] =\\n\", cache_conv[0][1][2][3])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mode = max\n",
      "A.shape = (2, 3, 3, 3)\n",
      "A =\n",
      " [[[[1.74481176 0.90159072 1.65980218]\n",
      "   [1.74481176 1.46210794 1.65980218]\n",
      "   [1.74481176 1.6924546  1.65980218]]\n",
      "\n",
      "  [[1.14472371 0.90159072 2.10025514]\n",
      "   [1.14472371 0.90159072 1.65980218]\n",
      "   [1.14472371 1.6924546  1.65980218]]\n",
      "\n",
      "  [[1.13162939 1.51981682 2.18557541]\n",
      "   [1.13162939 1.51981682 2.18557541]\n",
      "   [1.13162939 1.6924546  2.18557541]]]\n",
      "\n",
      "\n",
      " [[[1.19891788 0.84616065 0.82797464]\n",
      "   [0.69803203 0.84616065 1.2245077 ]\n",
      "   [0.69803203 1.12141771 1.2245077 ]]\n",
      "\n",
      "  [[1.96710175 0.84616065 1.27375593]\n",
      "   [1.96710175 0.84616065 1.23616403]\n",
      "   [1.62765075 1.12141771 1.2245077 ]]\n",
      "\n",
      "  [[1.96710175 0.86888616 1.27375593]\n",
      "   [1.96710175 0.86888616 1.23616403]\n",
      "   [1.62765075 1.12141771 0.79280687]]]]\n",
      "\n",
      "mode = average\n",
      "A.shape = (2, 3, 3, 3)\n",
      "A =\n",
      " [[[[-3.01046719e-02 -3.24021315e-03 -3.36298859e-01]\n",
      "   [ 1.43310483e-01  1.93146751e-01 -4.44905196e-01]\n",
      "   [ 1.28934436e-01  2.22428468e-01  1.25067597e-01]]\n",
      "\n",
      "  [[-3.81801899e-01  1.59993515e-02  1.70562706e-01]\n",
      "   [ 4.73707165e-02  2.59244658e-02  9.20338402e-02]\n",
      "   [ 3.97048605e-02  1.57189094e-01  3.45302489e-01]]\n",
      "\n",
      "  [[-3.82680519e-01  2.32579951e-01  6.25997903e-01]\n",
      "   [-2.47157416e-01 -3.48524998e-04  3.50539717e-01]\n",
      "   [-9.52551510e-02  2.68511000e-01  4.66056368e-01]]]\n",
      "\n",
      "\n",
      " [[[-1.73134159e-01  3.23771981e-01 -3.43175716e-01]\n",
      "   [ 3.80634669e-02  7.26706274e-02 -2.30268958e-01]\n",
      "   [ 2.03009393e-02  1.41414785e-01 -1.23158476e-02]]\n",
      "\n",
      "  [[ 4.44976963e-01 -2.61694592e-03 -3.10403073e-01]\n",
      "   [ 5.08114737e-01 -2.34937338e-01 -2.39611830e-01]\n",
      "   [ 1.18726772e-01  1.72552294e-01 -2.21121966e-01]]\n",
      "\n",
      "  [[ 4.29449255e-01  8.44699612e-02 -2.72909051e-01]\n",
      "   [ 6.76351685e-01 -1.20138225e-01 -2.44076712e-01]\n",
      "   [ 1.50774518e-01  2.89111751e-01  1.23238536e-03]]]]\n"
     ]
    }
   ],
   "source": [
    "# GRADED FUNCTION: pool_forward\n",
    "\n",
    "def pool_forward(A_prev, hparameters, mode = \"max\"):\n",
    "    \"\"\"\n",
    "    Implements the forward pass of the pooling layer\n",
    "\n",
    "    Arguments:\n",
    "    A_prev -- Input data, numpy array of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
    "    hparameters -- python dictionary containing \"f\" and \"stride\"\n",
    "    mode -- the pooling mode you would like to use, defined as a string (\"max\" or \"average\")\n",
    "\n",
    "    Returns:\n",
    "    A -- output of the pool layer, a numpy array of shape (m, n_H, n_W, n_C)\n",
    "    cache -- cache used in the backward pass of the pooling layer, contains the input and hparameters\n",
    "    \"\"\"\n",
    "\n",
    "    # Retrieve dimensions from the input shape\n",
    "    (m, n_H_prev, n_W_prev, n_C_prev) = A_prev.shape\n",
    "\n",
    "    # Retrieve hyperparameters from \"hparameters\"\n",
    "    f = hparameters[\"f\"]\n",
    "    stride = hparameters[\"stride\"]\n",
    "\n",
    "    # Define the dimensions of the output\n",
    "    n_H = int(1 + (n_H_prev - f) / stride)\n",
    "    n_W = int(1 + (n_W_prev - f) / stride)\n",
    "    n_C = n_C_prev\n",
    "\n",
    "    # Initialize output matrix A\n",
    "    A = np.zeros((m, n_H, n_W, n_C))\n",
    "\n",
    "    ### START CODE HERE ###\n",
    "    for i in range(m):                         # loop over the training examples\n",
    "        for h in range(n_H):                     # loop on the vertical axis of the output volume\n",
    "            # Find the vertical start and end of the current \"slice\" (≈2 lines)\n",
    "            vert_start = h * stride\n",
    "            vert_end = vert_start + f\n",
    "\n",
    "            for w in range(n_W):                 # loop on the horizontal axis of the output volume\n",
    "                # Find the vertical start and end of the current \"slice\" (≈2 lines)\n",
    "                horiz_start = w * stride\n",
    "                horiz_end = horiz_start + f\n",
    "\n",
    "                for c in range (n_C):            # loop over the channels of the output volume\n",
    "\n",
    "                    # Use the corners to define the current slice on the ith training example of A_prev, channel c. (≈1 line)\n",
    "                    a_prev_slice = A_prev[i, vert_start:vert_end, horiz_start : horiz_end, c]\n",
    "\n",
    "                    # Compute the pooling operation on the slice.\n",
    "                    # Use an if statement to differentiate the modes.\n",
    "                    # Use np.max and np.mean.\n",
    "                    if mode == \"max\":\n",
    "                        A[i, h, w, c] = np.max(a_prev_slice)\n",
    "                    elif mode == \"average\":\n",
    "                        A[i, h, w, c] = np.mean(a_prev_slice)\n",
    "\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    # Store the input and hparameters in \"cache\" for pool_backward()\n",
    "    cache = (A_prev, hparameters)\n",
    "\n",
    "    # Making sure your output shape is correct\n",
    "    assert(A.shape == (m, n_H, n_W, n_C))\n",
    "\n",
    "    return A, cache\n",
    "\n",
    "# Case 1: stride of 1\n",
    "np.random.seed(1)\n",
    "A_prev = np.random.randn(2, 5, 5, 3)\n",
    "hparameters = {\"stride\" : 1, \"f\": 3}\n",
    "\n",
    "A, cache = pool_forward(A_prev, hparameters)\n",
    "print(\"mode = max\")\n",
    "print(\"A.shape = \" + str(A.shape))\n",
    "print(\"A =\\n\", A)\n",
    "print()\n",
    "A, cache = pool_forward(A_prev, hparameters, mode = \"average\")\n",
    "print(\"mode = average\")\n",
    "print(\"A.shape = \" + str(A.shape))\n",
    "print(\"A =\\n\", A)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}